# SGR Research Agent - Configuration Template
# Production-ready configuration for Schema-Guided Reasoning
# Copy this file to config.yaml and fill in your API keys

# OpenAI API Configuration
openai:
  api_key: "your-openai-api-key-here"  # Required: Your OpenAI API key
  base_url: ""                         # Optional: Alternative URL (e.g., for proxy LiteLLM/vLLM)
  model: "gpt-4o-mini"                 # Model to use
  max_tokens: 8000                     # Maximum number of tokens
  temperature: 0.4                     # Generation temperature (0.0-1.0)
  proxy: ""                            # Example: "socks5://127.0.0.1:1081" or "http://127.0.0.1:8080" or leave empty for no proxy

# Tavily Search Configuration
tavily:
  api_key: "your-tavily-api-key-here"  # Required: Your Tavily API key
  api_base_url: "https://api.tavily.com"  # Tavily API base URL

# Confluence Configuration (Optional - for internal knowledge base search)
confluence:
  base_url: "https://conf.redmadrobot.com"  # Your Confluence base URL
  username: "your-username"                  # Confluence username
  password: "your-password-or-api-token"     # Confluence password or API token
  timeout: 30.0                              # Request timeout in seconds

# Smart Platform Configuration (Optional - for KNN/vector search in knowledge base)
smart_platform:
  base_url: "https://smartplatform-dev.neuraldeep.tech"  # Smart Platform API base URL
  api_key: "your-base64-encoded-credentials"              # Basic auth credentials (base64 encoded)
  agent_id: "your-agent-id-here"                          # Smart Platform agent ID
  chat_id: "your-chat-id-here"                            # Default chat ID for queries
  timeout: 30.0                                           # Request timeout in seconds

# Search Settings
search:
  max_results: 10                      # Maximum number of search results

# Scraping Settings
scraping:
  enabled: false                       # Enable full text scraping of found pages
  max_pages: 5                         # Maximum pages to scrape per search
  content_limit: 1500                  # Character limit for full content per source

# Execution Settings
execution:
  max_steps: 6                         # Maximum number of execution steps
  reports_dir: "reports"               # Directory for saving reports
  logs_dir: "logs"                     # Directory for saving reports

# Prompts Settings
prompts:
  prompts_dir: "prompts"               # Directory with prompts
  system_prompt_file: "system_prompt.txt"  # System prompt file
