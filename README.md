# SGR Research Agent - Two-Phase Architecture

A sophisticated research agent that combines **Schema-Guided Reasoning (SGR)** with **OpenAI Function Calls** to create a natural, interpretable, and powerful research workflow.

## ğŸ§  Core Innovation: Two-Phase Approach

Traditional agents either use pure function calls (losing reasoning transparency) or structured output with local execution (missing natural LLM behavior). This agent combines the best of both worlds:

### Phase 1: Reasoning (SGR)
- **Reasoning as a Tool** - `generate_reasoning` function call
- Controlled via `tool_choice="generate_reasoning"` 
- **Structured Output** for explicit reasoning analysis
- Model explains **what** to do and **why**
- Pure analytical thinking without tool execution
- Full transparency into decision-making process

### Phase 2: Action (Function Calls)
- **Native OpenAI Function Calls** with `tool_choice="auto"`
- Model naturally chooses appropriate tools based on reasoning
- Preserves LLM's natural conversation flow
- No disruption to chat template or message structure

## ğŸ—ï¸ Architecture Benefits

### âœ… Natural LLM Behavior
- **Both phases use native OpenAI function calling**
- Phase 1: `tool_choice="generate_reasoning"` - forced reasoning
- Phase 2: `tool_choice="auto"` - natural tool selection
- Maintains proper chat message flow throughout
- Model decides tool usage naturally within OpenAI's framework
- No artificial constraints on LLM behavior

### âœ… Complete Interpretability
- Every decision is explicitly reasoned
- Clear explanation of **why** each action is taken
- Transparent thought process at each step
- Easy debugging and understanding

### âœ… Adaptive Planning
- Real-time adaptation based on new information
- Context-aware decision making
- Anti-cycling mechanisms to prevent loops
- Dynamic re-planning when needed

### âœ… Clean Architecture
- Modular design with clear separation of concerns
- Easy to extend and modify
- Type-safe with Pydantic models
- Comprehensive configuration system

## ğŸ“ Project Structure

```
â”œâ”€â”€ sgr_agent.py          # ğŸ¯ Main orchestration engine
â”œâ”€â”€ models.py             # ğŸ“Š Pydantic models for type safety
â”œâ”€â”€ tool_schemas.py       # ğŸ› ï¸ OpenAI function schemas  
â”œâ”€â”€ executors.py          # âš¡ Tool execution logic
â”œâ”€â”€ prompts.yaml          # ğŸ’¬ System prompts configuration
â”œâ”€â”€ config.yaml.example   # âš™ï¸ Configuration template
â””â”€â”€ requirements.txt      # ğŸ“¦ Python dependencies
```

## ğŸ”„ Workflow Deep Dive

```mermaid
graph TD
    A[User Query] --> B[Phase 1: SGR Analysis]
    B --> C[Structured Output Call]
    C --> D[ReasoningStep Model]
    D --> E{Validation}
    E -->|Pass| F[Phase 2: Tool Execution]
    E -->|Fail| B
    F --> G[Function Calls Auto]
    G --> H[Local Tool Execution]
    H --> I[Update Context]
    I --> J{Task Complete?}
    J -->|No| B
    J -->|Yes| K[Generate Report]
    K --> L[Task Completion]
```

### Phase 1: Schema-Guided Reasoning as a Tool
```python
# Reasoning is implemented as a proper OpenAI function call
completion = client.chat.completions.create(
    tools=ALL_TOOLS,
    tool_choice={"type": "function", "function": {"name": "generate_reasoning"}},
    messages=conversation_history
)

# Inside generate_reasoning tool - Structured Output call
class ReasoningStep(BaseModel):
    reasoning_steps: List[str]           # Step-by-step analysis
    current_situation: str               # Current state assessment  
    next_action: Literal["search", "clarify", "report", "complete"]
    action_reasoning: str                # Why this action is needed
    task_completed: bool                 # Completion status
    # ... additional fields for progress tracking
```

**Key Innovation**: Reasoning is a **tool call**, not a separate API call:
- Model naturally calls `generate_reasoning` function
- Function internally uses Structured Output for analysis
- Returns structured reasoning to conversation history
- Maintains proper OpenAI message flow: assistant â†’ tool â†’ user
- No breaks in chat template or conversation structure

### Phase 2: Natural Function Calling
After reasoning, the model naturally calls appropriate tools:
```python
# Model decides which tools to call based on reasoning
completion = client.chat.completions.create(
    tools=ALL_TOOLS,
    tool_choice="auto",  # Let model decide naturally
    messages=conversation_history
)
```

Available tools:
- `generate_reasoning`: Analyze situation and plan next action (Phase 1)
- `web_search`: Research information with Tavily
- `clarification`: Ask user for clarification
- `create_report`: Generate comprehensive research report
- `report_completion`: Mark task as finished

**Note**: `generate_reasoning` is controlled via `tool_choice`, while other tools are selected naturally by the model via `tool_choice="auto"`.

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure API Keys
```bash
export OPENAI_API_KEY="your-openai-key"
export TAVILY_API_KEY="your-tavily-key"
```

Or create `config.yaml`:
```yaml
openai:
  api_key: "your-openai-key"
  model: "gpt-4o-mini"
  temperature: 0.3

tavily:
  api_key: "your-tavily-key"

execution:
  max_rounds: 8
  max_searches_total: 6
```

### 3. Run the Agent
```bash
python sgr_agent.py
```

### 4. Example Usage
```
ğŸ” Enter research task: Analyze BMW M6 reliability and pricing trends

ğŸ§  Reasoning Analysis
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Current         â”‚ User wants BMW M6 analysis             â”‚
â”‚ Next action     â”‚ search                                 â”‚  
â”‚ Action reasoningâ”‚ Need pricing and reliability data      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ” Search: 'BMW M6 reliability reviews 2024'
   1. [1] BMW M6 Long-term Review â€” motortrend.com
   2. [2] M6 Reliability Issues â€” bmwblog.com
   ...
```

## ğŸ¯ Why This Architecture Works

### 1. **Preserves LLM Nature**
Unlike pure structured output approaches, this preserves the LLM's natural conversational flow. The model can think, reason, and then act naturally.

### 2. **No Chat Template Disruption**
**Both phases use OpenAI's native function calling interface**:
- Phase 1: Reasoning via `tool_choice="generate_reasoning"` 
- Phase 2: Actions via `tool_choice="auto"`
- Conversation history remains clean and proper
- Natural assistant â†’ tool â†’ user message flow
- No artificial API calls or conversation breaks
- Maintains intended chat template structure throughout

### 3. **Complete Transparency**
Every decision is reasoned explicitly. You can see exactly why the model chose each action, making debugging and improvement straightforward.

### 4. **Adaptive Behavior**
The model can change its plan based on new information, handle unexpected results, and adapt its strategy dynamically.

### 5. **Type Safety**
Pydantic models ensure data integrity throughout the pipeline, catching errors early and providing clear interfaces.

## ğŸ”§ Configuration

### Environment Variables
- `OPENAI_API_KEY`: Your OpenAI API key
- `TAVILY_API_KEY`: Your Tavily search API key  
- `OPENAI_MODEL`: Model to use (default: gpt-4o-mini)
- `MAX_ROUNDS`: Maximum research rounds (default: 8)
- `MAX_SEARCHES_TOTAL`: Maximum searches per session (default: 6)

### Advanced Configuration
Edit `prompts.yaml` to customize system prompts:
```yaml
structured_output_reasoning:
  template: |
    You are a reasoning module...
    # Customize reasoning instructions

outer_system:
  template: |
    You are an expert researcher...
    # Customize main system prompt
```

## ğŸ§ª Example Research Session

```
User: "Research Tesla Model S vs BMW i7 electric luxury sedans"

Round 1 - Reasoning + Action
â”œâ”€â”€ ğŸ§  Analysis: Need pricing and specs comparison
â”œâ”€â”€ ğŸ” Search: "Tesla Model S 2024 price specifications"
â””â”€â”€ ğŸ“Š Results: 10 sources found

Round 2 - Reasoning + Action  
â”œâ”€â”€ ğŸ§  Analysis: Have Tesla data, need BMW i7 info
â”œâ”€â”€ ğŸ” Search: "BMW i7 2024 electric sedan review price"
â””â”€â”€ ğŸ“Š Results: 8 sources found

Round 3 - Reasoning + Action
â”œâ”€â”€ ğŸ§  Analysis: Sufficient data for comparison report
â”œâ”€â”€ ğŸ“„ Report: "Tesla Model S vs BMW i7 Comparison"
â””â”€â”€ âœ… Completion: Task finished successfully

ğŸ“Š Session Stats: 2 searches | 18 sources | 1 report generated
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes with type hints and tests
4. Update documentation as needed
5. Submit a pull request

## ğŸ“ License

MIT License - see LICENSE file for details.

## ğŸ”— Related Work

- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [Pydantic Models](https://docs.pydantic.dev/)
- [Tavily Search API](https://tavily.com/)

---

*Built with â¤ï¸ for transparent, powerful AI research automation*
